# v0.9.0 - Optimized

## Overview

This release begins the Performance Phase by profiling and optimizing hot paths. The focus is on improving runtime performance, reducing memory usage, and cleaning up dead code.

**Phase**: Performance
**Duration**: 2 weeks
**Prerequisites**: v0.8.0 (process safety complete, Robustness Phase done)

## Objectives

1. Profile critical hot paths
2. Optimize neuron forward propagation
3. Optimize weight perturbation and mutation
4. Optimize Mnesia database access
5. Remove dead code and unused fields
6. Add performance benchmarks

## Profiling and Optimization

### 1. Identify Hot Paths

**Expected Hot Paths**:
- Neuron forward propagation (signal processing)
- Weight perturbation during tuning
- Fitness calculation and aggregation
- Mnesia reads during mutation

**Profiling Approach**:
```erlang
%% Profile with fprof
profile_evolution() ->
    fprof:trace(start),
    population_monitor:run_evolution(TestPopulation),
    fprof:trace(stop),
    fprof:profile(),
    fprof:analyse([{dest, "evolution_profile.txt"}]).

%% Profile specific function
profile_neuron_forward() ->
    eprof:start(),
    eprof:start_profiling([self()]),
    [neuron_forward_test() || _ <- lists:seq(1, 10000)],
    eprof:stop_profiling(),
    eprof:analyze().
```

### 2. Optimize Neuron Forward Propagation

**Current Bottlenecks**:
- List operations in signal aggregation
- Weight tuple unpacking
- Activation function calls

**Optimizations**:

```erlang
%% Optimization 1: Use list comprehension instead of recursion
%% Before
dot_product_old([], [], Acc) -> Acc;
dot_product_old([{W,_,_,_}|Ws], [I|Is], Acc) ->
    dot_product_old(Ws, Is, Acc + W * I).

%% After (2-3x faster for large lists)
dot_product(Weights, Inputs) ->
    lists:sum([W * I || {{W,_,_,_}, I} <- lists:zip(Weights, Inputs)]).

%% Optimization 2: Pre-extract weights for repeated use
%% Before: unpack tuple every time
%% After: extract weights once during initialization
prepare_weights(WeightSpecs) ->
    [W || {W, _, _, _} <- WeightSpecs].

%% Use extracted weights for computation
dot_product_fast(Weights, Inputs) ->
    lists:sum([W * I || {W, I} <- lists:zip(Weights, Inputs)]).
```

**Activation Function Optimization**:
```erlang
%% Use NIF for expensive math (if needed)
%% Or use lookup tables for approximation

%% Cache frequently used values
-define(TANH_CACHE_SIZE, 1000).

init_tanh_cache() ->
    Cache = ets:new(tanh_cache, [set, public, named_table]),
    [ets:insert(Cache, {X, math:tanh(X)})
     || X <- generate_cache_keys(?TANH_CACHE_SIZE)],
    ok.

tanh_cached(X) when X >= -5.0, X =< 5.0 ->
    %% Use cache for common range
    Key = round(X * 100) / 100,
    case ets:lookup(tanh_cache, Key) of
        [{Key, Val}] -> Val;
        [] -> math:tanh(X)
    end;
tanh_cached(X) ->
    math:tanh(X).
```

### 3. Optimize Weight Perturbation

**Current Issues**:
- Random number generation overhead
- Multiple list traversals

**Optimizations**:
```erlang
%% Optimization 1: Generate random batch
%% Before: call rand:uniform() per weight
perturb_weights_old(Weights, Spread) ->
    [perturb_weight(W, Spread) || W <- Weights].

%% After: generate random values in batch
perturb_weights(Weights, Spread) ->
    N = length(Weights),
    Randoms = [rand:uniform() - 0.5 || _ <- lists:seq(1, N)],
    lists:zipwith(
        fun({W, DW, LP, LPs}, R) ->
            NewDW = R * Spread + DW * 0.5,
            {functions:sat(W + NewDW, ?SAT_LIMIT), NewDW, LP, LPs}
        end,
        Weights,
        Randoms
    ).

%% Optimization 2: Use binary for large weight vectors
%% Store weights as binary for memory efficiency
-spec weights_to_binary([weight_spec()]) -> binary().
weights_to_binary(Weights) ->
    << <<W:64/float, DW:64/float, LP:64/float>>
       || {W, DW, LP, _} <- Weights >>.
```

### 4. Optimize Mnesia Access

**Current Issues**:
- Synchronous reads in hot paths
- Transaction overhead
- No caching

**Optimizations**:
```erlang
%% Optimization 1: Use dirty reads where safe
%% Before: transaction
read_neuron_old(NeuronId) ->
    mnesia:transaction(fun() ->
        mnesia:read({neuron, NeuronId})
    end).

%% After: dirty read (faster, acceptable for reads)
read_neuron(NeuronId) ->
    case mnesia:dirty_read({neuron, NeuronId}) of
        [Neuron] -> {ok, Neuron};
        [] -> {error, not_found}
    end.

%% Optimization 2: Batch reads
read_neurons(NeuronIds) ->
    [read_neuron(Id) || Id <- NeuronIds].

%% Optimization 3: Cache genotype during evaluation
%% Load genotype once, keep in process state
cache_genotype(AgentId) ->
    Agent = genotype:read_agent(AgentId),
    Neurons = genotype:read_neurons(AgentId),
    Sensors = genotype:read_sensors(AgentId),
    #{
        agent => Agent,
        neurons => maps:from_list([{N#neuron.id, N} || N <- Neurons]),
        sensors => maps:from_list([{S#sensor.id, S} || S <- Sensors])
    }.
```

### 5. Remove Dead Code

**Tasks**:

1. **Remove commented-out code**
   - functions.erl: remove commented functions
   - Any module with large commented sections

2. **Remove unused record fields**
   ```erlang
   %% In neuron.erl
   %% Before: unused fields
   -record(state, {
       ...,
       si_pids=[],              % UNUSED - remove
       pre_processor,           % UNUSED - remove
       signal_integrator,       % UNUSED - remove
       post_processor,          % UNUSED - remove
       ...
   }).

   %% After: clean record
   -record(neuron_state, {
       ...,
       %% Only used fields
   }).
   ```

3. **Remove unused exports**
   - Audit all module exports
   - Remove functions only exported but never called

4. **Clean up macros**
   - Remove unused -define macros
   - Document remaining macros

### 6. Add Performance Benchmarks

```erlang
-module(tweann_benchmark).
-export([run_all/0, benchmark_forward/0, benchmark_mutation/0]).

%% Run all benchmarks
run_all() ->
    Results = [
        {forward_propagation, benchmark_forward()},
        {weight_perturbation, benchmark_perturbation()},
        {mutation_operators, benchmark_mutation()},
        {mnesia_access, benchmark_mnesia()}
    ],
    print_results(Results).

%% Benchmark forward propagation
benchmark_forward() ->
    %% Setup
    Network = test_helpers:create_benchmark_network(100),  % 100 neurons

    %% Warm up
    [run_forward_pass(Network) || _ <- lists:seq(1, 100)],

    %% Benchmark
    {Time, _} = timer:tc(fun() ->
        [run_forward_pass(Network) || _ <- lists:seq(1, 1000)]
    end),

    #{
        total_ms => Time / 1000,
        per_pass_us => Time / 1000,
        passes => 1000
    }.

%% Benchmark mutation
benchmark_mutation() ->
    {ok, AgentId} = test_helpers:create_benchmark_agent(),

    {Time, _} = timer:tc(fun() ->
        [genome_mutator:mutate_weights(AgentId)
         || _ <- lists:seq(1, 100)]
    end),

    test_helpers:cleanup_test_agent(AgentId),

    #{
        total_ms => Time / 1000,
        per_mutation_us => Time / 100,
        mutations => 100
    }.
```

## Tests to Write

### performance_test.erl

```erlang
-module(performance_test).
-include_lib("eunit/include/eunit.hrl").

%% ============================================================================
%% Performance regression tests
%% ============================================================================

forward_propagation_performance_test() ->
    %% Ensure forward pass completes in acceptable time
    Network = test_helpers:create_test_network(50),
    MaxTime = 1000,  % microseconds

    {Time, _Result} = timer:tc(fun() ->
        run_forward_pass(Network)
    end),

    ?assert(Time < MaxTime).

weight_perturbation_performance_test() ->
    %% Ensure perturbation is fast enough
    Weights = [create_weight_spec() || _ <- lists:seq(1, 1000)],
    MaxTime = 1000,  % microseconds

    {Time, _Result} = timer:tc(fun() ->
        perturbation_utils:perturb_weights(Weights, 0.1)
    end),

    ?assert(Time < MaxTime).

mnesia_read_performance_test() ->
    %% Dirty read should be fast
    {ok, AgentId} = test_helpers:create_test_agent_in_db(),
    NeuronIds = genotype:get_neuron_ids(AgentId),
    MaxTime = 100,  % microseconds per neuron

    {Time, _} = timer:tc(fun() ->
        [genotype:read_neuron(Id) || Id <- NeuronIds]
    end),

    PerNeuron = Time / length(NeuronIds),
    ?assert(PerNeuron < MaxTime),

    test_helpers:cleanup_test_agent(AgentId).

%% ============================================================================
%% Memory tests
%% ============================================================================

neuron_memory_usage_test() ->
    %% Ensure neuron state doesn't grow unboundedly
    InitialMemory = erlang:memory(processes),

    %% Create many neurons
    Pids = [spawn(fun neuron_test_loop/0) || _ <- lists:seq(1, 100)],

    FinalMemory = erlang:memory(processes),
    MemoryPerNeuron = (FinalMemory - InitialMemory) / 100,

    %% Cleanup
    [Pid ! stop || Pid <- Pids],

    %% Should be reasonable (< 10KB per neuron)
    ?assert(MemoryPerNeuron < 10240).

neuron_test_loop() ->
    receive stop -> ok end.
```

### optimization_verification_test.erl

```erlang
-module(optimization_verification_test).
-include_lib("eunit/include/eunit.hrl").

%% ============================================================================
%% Verify optimizations maintain correctness
%% ============================================================================

dot_product_optimization_correctness_test() ->
    %% Old and new implementation should produce same results
    Weights = [{0.5, 0.0, 0.1, []}, {0.3, 0.0, 0.1, []}],
    Inputs = [0.8, 0.6],

    %% Results should match
    OldResult = signal_aggregator:dot_product_reference(Weights, Inputs),
    NewResult = signal_aggregator:dot_product(Weights, Inputs),

    ?assert(abs(OldResult - NewResult) < 0.0001).

perturbation_optimization_correctness_test() ->
    %% Optimized perturbation should still perturb
    Weights = [{0.5, 0.0, 0.1, []} || _ <- lists:seq(1, 10)],
    Spread = 1.0,

    Perturbed = perturbation_utils:perturb_weights(Weights, Spread),

    %% Should be different
    ?assertNotEqual(Weights, Perturbed),
    %% Should have same structure
    ?assertEqual(length(Weights), length(Perturbed)).

cached_tanh_accuracy_test() ->
    %% Cached tanh should be accurate
    TestValues = [0.0, 0.5, 1.0, -0.5, -1.0, 2.5],

    lists:foreach(
        fun(X) ->
            Expected = math:tanh(X),
            Actual = functions:tanh_cached(X),
            ?assert(abs(Expected - Actual) < 0.01)
        end,
        TestValues
    ).
```

## Documentation Requirements

### Required Documentation

1. **Performance characteristics**
   - Hot path descriptions
   - Expected performance metrics
   - Benchmark results

2. **Optimization techniques**
   - Each optimization documented
   - Trade-offs explained

3. **Configuration guide**
   - Cache sizes
   - Batch sizes

### Documentation Checklist

- [ ] Hot paths identified and documented
- [ ] Optimizations explained
- [ ] Benchmark usage documented
- [ ] Configuration options listed

## Quality Gates

### v0.9.0 Acceptance Criteria

1. **Performance**
   - [ ] Forward propagation < 1ms for 100 neurons
   - [ ] Weight perturbation < 1ms for 1000 weights
   - [ ] Mnesia read < 100us per record

2. **Dead Code Removal**
   - [ ] No commented-out code
   - [ ] No unused record fields
   - [ ] No unused exports

3. **Benchmarks**
   - [ ] Benchmark suite complete
   - [ ] Baseline metrics recorded
   - [ ] No performance regressions

4. **Optimization Correctness**
   - [ ] All optimizations verified
   - [ ] Results match reference implementation
   - [ ] All tests pass

5. **Static Analysis**
   - [ ] Zero dialyzer warnings

## Known Limitations

- Some optimizations are micro-optimizations
- Cache requires memory overhead
- Dirty reads sacrifice consistency guarantees

## Investigation: Real-Time Learning and Multi-Modal Evolution

**Objective**: Investigate approaches to enable real-time learning and potentially support multiple learning modalities simultaneously.

**Background**:
Current TWEANN is offline evolution only:
- Evolution happens between episodes, not during
- No weight updates during agent lifetime
- Generational selection process

Real-time learning would enable:
- Online adaptation (RL, adaptive control, robotics)
- Learning during gameplay/deployment
- Continuous improvement without resets
- Hybrid evolution + learning strategies

**Key Research Areas**:

### 1. Online Weight Adaptation (Baldwin Effect)

Keep topology evolution offline, add real-time weight learning:

```erlang
%% Add learning rule to neuron state
-record(neuron_state, {
    ...,
    learning_rule = none,        % none | delta_rule | hebbian | anti_hebbian
    learning_rate = 0.01,
    plasticity_decay = 0.999     % decay learning over time
}).

%% Neuron receives error signal and updates weights
handle_error_signal(Error, State) ->
    case State#state.learning_rule of
        delta_rule ->
            UpdatedWeights = apply_delta_rule(
                State#state.weights,
                State#state.last_inputs,
                Error,
                State#state.learning_rate
            ),
            State#state{weights = UpdatedWeights};
        hebbian ->
            UpdatedWeights = apply_hebbian(
                State#state.weights,
                State#state.last_inputs,
                State#state.last_output
            ),
            State#state{weights = UpdatedWeights};
        _ ->
            State
    end.
```

**Approach**: Add optional learning rules to neurons, keep offline topology evolution.

### 2. Continuous Evolution (No Discrete Generations)

Evolve population continuously - agents born/die in rolling window:

```erlang
%% Continuous population monitor
-record(continuous_population, {
    active_agents,              % Currently running agents
    fitness_window,             % Recent fitness scores
    birth_queue,                % Pending offspring
    death_queue,                % Agents to terminate
    max_population = 100,
    replacement_rate = 0.1      % Replace 10% continuously
}).

%% Replace worst performers with offspring of best
continuous_evolution_step(Population) ->
    %% Sort by recent fitness window
    Sorted = sort_by_windowed_fitness(Population#continuous_population.active_agents),

    %% Bottom 10% die
    {ToKill, Survivors} = lists:split(
        round(length(Sorted) * Population#continuous_population.replacement_rate),
        Sorted
    ),

    %% Top 10% reproduce
    {Parents, _} = lists:split(
        round(length(Sorted) * Population#continuous_population.replacement_rate),
        lists:reverse(Sorted)
    ),

    %% Create offspring
    Offspring = [create_offspring(Parent) || Parent <- Parents],

    %% Update population
    Population#continuous_population{
        active_agents = Survivors ++ Offspring
    }.
```

**Approach**: Rolling window fitness, continuous birth/death, no generations.

### 3. Evolved Plasticity (HyperNEAT-style)

Evolve the learning rules themselves, not just topology:

```erlang
%% Add plasticity genes to neuron records
-record(neuron, {
    ...,
    plasticity_genes = #{
        learning_rule => hebbian,
        learning_rate => 0.01,
        modulation_input => bias,    % or sensor signal
        learning_window => 100       % time steps
    }
}).

%% Mutations can now modify learning behavior
mutate_plasticity(NeuronId) ->
    Neuron = genotype:read_neuron(NeuronId),
    Plasticity = Neuron#neuron.plasticity_genes,

    %% Mutate learning rule type
    NewLearningRule = case rand:uniform() of
        R when R < 0.25 -> hebbian;
        R when R < 0.50 -> anti_hebbian;
        R when R < 0.75 -> delta_rule;
        _ -> oja_rule
    end,

    %% Mutate learning rate
    NewLearningRate = functions:sat(
        maps:get(learning_rate, Plasticity) + (rand:uniform() - 0.5) * 0.01,
        0.0,
        0.1
    ),

    UpdatedPlasticity = Plasticity#{
        learning_rule => NewLearningRule,
        learning_rate => NewLearningRate
    },

    genotype:update_neuron(NeuronId, Neuron#neuron{plasticity_genes = UpdatedPlasticity}).
```

**Approach**: Evolve how to learn, agents adapt during lifetime using evolved rules.

### 4. Multi-Modal Evolution (Hybrid Strategies)

Support multiple learning modalities simultaneously:

```erlang
%% Multi-modal agent configuration
-record(agent, {
    ...,
    evolution_mode = #{
        topology_evolution => true,       % TWEANN structure evolution
        weight_evolution => true,          % Evolutionary weight optimization
        online_learning => hebbian,        % Real-time weight adaptation
        meta_learning => false,            % Learn learning rules
        speciation => behavioral,          % Diversity preservation
        fitness_aggregation => pareto      % Multi-objective
    }
}).

%% Population can have mixed strategies
-record(population, {
    ...,
    allowed_modes = [
        #{topology_evolution => true, online_learning => false},     % Pure TWEANN
        #{topology_evolution => true, online_learning => hebbian},   % Baldwin effect
        #{topology_evolution => false, online_learning => delta_rule}, % Fixed topology + learning
        #{meta_learning => true, online_learning => evolved}         % Evolved plasticity
    ]
}).
```

**Approach**: Each agent can use different combination of evolution + learning strategies.

### 5. Implementation Considerations

**Challenges**:
- Feedback signals: Where does error/reward come from?
- Stability vs plasticity: Catastrophic forgetting
- Process overhead: Frequent weight updates
- Credit assignment: Which neurons to update?

**Process Architecture**:
```erlang
%% Neuron receives both activation and learning messages
neuron_loop(State) ->
    receive
        {forward, From, Input} ->
            %% Normal forward pass
            Output = activate(Input, State),
            From ! {neuron, self(), Output},
            neuron_loop(State#state{last_input = Input, last_output = Output});

        {learn, From, ErrorOrReward} ->
            %% Online weight update
            NewState = update_weights_online(ErrorOrReward, State),
            From ! {learned, self()},
            neuron_loop(NewState);

        {get_weights, From} ->
            %% Extract learned weights for genotype
            From ! {weights, State#state.weights},
            neuron_loop(State)
    end.
```

**Genotype Feedback Loop**:
```erlang
%% After evaluation, optionally save learned weights to genotype
save_learned_weights(AgentId, Phenotype) ->
    %% Query all neurons for current weights
    LearnedWeights = [{NId, get_neuron_weights(NPid)}
                      || {NId, NPid} <- Phenotype#phenotype.neuron_pids],

    %% Update genotype with learned weights
    [genotype:update_neuron_weights(NId, Weights)
     || {NId, Weights} <- LearnedWeights],

    ok.
```

### 6. Investigation Plan

**Phase 1: Prototype Online Weight Learning (3-4 days)**
1. Add learning_rule field to neuron records
2. Implement delta rule and Hebbian learning
3. Test with simple RL problem (cart-pole)
4. Measure: learning speed, stability, overhead

**Phase 2: Prototype Continuous Evolution (3-4 days)**
1. Modify population_monitor for continuous mode
2. Implement rolling window fitness
3. Test convergence vs generational
4. Measure: diversity, solution quality

**Phase 3: Design Multi-Modal Architecture (2-3 days)**
1. Design agent mode configuration
2. Prototype mode mixing in population
3. Document trade-offs and use cases

**Phase 4: Evaluation & Recommendation (2 days)**
1. Compare approaches on benchmark problems
2. Document benefits and limitations
3. Recommend implementation priority
4. Update roadmap based on findings

**Total Investigation Effort**: 10-13 days

### 7. Decision Criteria

**Implement Online Learning if**:
- >2x faster convergence on RL tasks
- Weights stabilize after initial learning
- Process overhead < 20%
- Clear use cases identified

**Implement Continuous Evolution if**:
- Better diversity maintenance than generational
- Smoother fitness improvement curve
- Suitable for online/streaming scenarios

**Implement Multi-Modal if**:
- Different problems benefit from different modes
- Mode mixing shows emergent benefits
- Configuration complexity is manageable

### 8. Expected Outcomes

1. **Technical Report**: Comparison of approaches with benchmarks
2. **Prototype Implementation**: Basic online learning or continuous evolution
3. **Roadmap Update**: Priority and timeline for full implementation
4. **Documentation**: Guidelines for when to use each mode

**References**:
- Stanley, K.O. "Compositional Pattern Producing Networks" (2007) - HyperNEAT plasticity
- Soltoggio, A. "Evolutionary advantages of neuromodulated plasticity" (2008)
- Floreano, D. "Neuroevolution: from architectures to learning" (2008)
- Clune, J. "The evolutionary origins of modularity" (2013) - Evolved learning rules

## Additional Behaviour Refactoring for v0.10.0+

Following the successful morphology behaviour pattern from v0.9.0, these additional aspects could benefit from the behaviour approach to increase library extensibility:

### 1. Fitness Postprocessor Behaviour (HIGH PRIORITY)

**Current**: Hardcoded strategies (size_proportional, normalize, pareto_dominance)

**Proposed Interface**:
```erlang
-behaviour(fitness_postprocessor_behaviour).
-callback process(AgentFitnessList, Options) -> AdjustedFitnessList.
```

**Benefits**:
- Custom fitness transformations (age-based, novelty search, custom parsimony)
- Domain-specific multi-objective aggregations
- User-defined fitness shaping without library modification

**Examples**: fitness_simplicity, fitness_age_based, fitness_novelty

**Priority**: HIGH - Fitness postprocessing is highly domain-specific

### 2. Selection Algorithm Behaviour (HIGH PRIORITY)

**Current**: Hardcoded strategies (competition, tournament, steady_state)

**Proposed Interface**:
```erlang
-behaviour(selection_algorithm_behaviour).
-callback select_survivors(Population, SurvivalRate, Options) -> Survivors.
```

**Benefits**:
- Exotic selection strategies (lexicase, MAP-Elites, novelty)
- Island model migrations, co-evolutionary selection
- Niching and diversity preservation strategies

**Examples**: selection_lexicase, selection_novelty, selection_map_elites

**Priority**: HIGH - Selection strategy is problem-specific

### 3. Mutation Operator Behaviour (MEDIUM PRIORITY)

**Current**: All mutations in one large genome_mutator module

**Proposed Interface**:
```erlang
-behaviour(mutation_operator_behaviour).
-callback mutate(AgentId, Constraint) -> ok | {error, Reason}.
-callback weight() -> float().  % For roulette wheel selection
-callback description() -> string().
```

**Benefits**:
- Custom topological mutations (skip connections, pruning)
- Domain-specific structural changes
- Modular mutation operators that can be added/removed
- Easier experimentation with new operators

**Examples**: mutation_add_skip_connection, mutation_prune_neuron, mutation_modularity

**Priority**: MEDIUM - Requires careful design due to genotype coupling

### 4. Species Identifier Behaviour (LOWER PRIORITY)

**Current**: Distance-based speciation with fingerprints

**Proposed Interface**:
```erlang
-behaviour(species_identifier_behaviour).
-callback identify_species(Population, Threshold) -> SpeciesList.
-callback calculate_distance(Agent1, Agent2) -> Distance.
```

**Benefits**:
- Behavioral distance (output-based similarity)
- Genealogical distance
- Custom similarity metrics

**Priority**: LOWER - Current implementation is fairly general

### Implementation Recommendation

**For v0.10.0**, prioritize:
1. **Fitness Postprocessor Behaviour** - Most requested customization point
2. **Selection Algorithm Behaviour** - Highly problem-dependent

These two provide the highest user value with well-defined boundaries and clear contracts. Mutation operator behaviour should be deferred until genotype architecture is more stable.

**Design Pattern**: Follow the morphology pattern:
- Create behaviour module (-behaviour directive, -callback specs)
- Create registry (gen_server with register/unregister/get/list_all)
- Refactor existing module to delegate to registry
- Extract built-in strategies to examples/
- Add comprehensive guide in guides/

**Estimated Effort**:
- Fitness Postprocessor: 1 week (behavior, registry, 3 examples, tests, guide)
- Selection Algorithm: 1 week (behavior, registry, 3 examples, tests, guide)
- Total: 2 weeks for both

## Next Steps

After v0.9.0 completion:

1. **Real-Time Learning Investigation** - Prototype and evaluate approaches
2. **Additional Behaviours for v0.10.0** - Fitness and Selection extensibility
3. **v1.0.0** - Finalize documentation and declare production readiness
4. Performance Phase complete
5. Full release validation

## Implementation Notes

### Profiling Workflow

1. Run baseline profiling
2. Identify top 5 hotspots
3. Implement optimization
4. Re-profile to verify improvement
5. Run correctness tests
6. Update benchmarks

### Cache Configuration

```erlang
%% In app configuration
{tweann, [
    {tanh_cache_size, 1000},
    {genotype_cache_ttl, 60000},  % 60 seconds
    {batch_read_size, 100}
]}
```

### Optimization Priority Order

1. **High Impact**: Signal aggregation, forward pass
2. **Medium Impact**: Weight perturbation, mutation
3. **Low Impact**: Logging, error handling

### Investigation: Nx Integration for Numerical Performance

**Objective**: Evaluate feasibility and benefits of integrating Elixir's Nx library (Numerical Elixir) for high-performance numerical computations.

**Background**:
- Nx provides tensor operations with optional GPU/CPU acceleration via backends
- Uses EXLA (XLA compiler) or Torchx (LibTorch) for compiled numerical operations
- May offer significant speedup for vector/matrix operations in neural networks

**Key Questions to Answer**:

1. **Compatibility**:
   - Can Erlang code call Nx NIFs directly?
   - Is Elixir dependency acceptable for pure Erlang library?
   - Interop overhead vs performance gain

2. **Performance Targets**:
   - Dot product computation (signal aggregation)
   - Weight vector operations (perturbation, mutation)
   - Activation function batching
   - Matrix operations for substrate networks (HyperNEAT)

3. **Implementation Approaches**:

   **Option A: Optional Elixir Dependency**
   ```erlang
   %% rebar.config
   {deps, [
       {nx, {git, "https://github.com/elixir-nx/nx.git", {tag, "v0.7.0"}}},
       {exla, {git, "https://github.com/elixir-nx/nx.git", {tag, "v0.7.0"}}}
   ]}.

   %% Use Nx if available, fallback to pure Erlang
   -ifdef(NX_AVAILABLE).
   dot_product(Weights, Inputs) ->
       nx_ops:dot_product(Weights, Inputs).
   -else.
   dot_product(Weights, Inputs) ->
       lists:sum([W * I || {W, I} <- lists:zip(Weights, Inputs)]).
   -endif.
   ```

   **Option B: Separate Acceleration Module**
   ```erlang
   %% src/tweann_accelerator.erl (optional module)
   -module(tweann_accelerator).
   -export([dot_product/2, batch_activate/2]).

   %% Use Nx tensors for bulk operations
   dot_product(WeightTensor, InputTensor) ->
       Nx.dot(WeightTensor, InputTensor).

   batch_activate(Signals, ActivationFn) ->
       Nx.map(Signals, activation_to_nx_fn(ActivationFn)).
   ```

   **Option C: Pure NIF Implementation**
   ```erlang
   %% Custom NIF using Rustler or C
   %% No Elixir dependency, maximum performance
   -module(tweann_nif).
   -on_load(init/0).

   init() ->
       SoName = filename:join(priv_dir(), "tweann_nif"),
       erlang:load_nif(SoName, 0).

   %% Implemented in Rust/C
   dot_product(_Weights, _Inputs) ->
       erlang:nif_error(not_loaded).
   ```

4. **Benchmarking Plan**:
   - Profile current pure Erlang performance
   - Implement Nx prototype for dot product
   - Measure overhead: data conversion, NIF calls
   - Compare: Small vectors (10), Medium (100), Large (1000)
   - Measure on: CPU only, GPU (if available)

5. **Decision Criteria**:
   - **Adopt Nx if**: >3x speedup for common operations, minimal overhead
   - **Custom NIF if**: Nx overhead too high, need fine control
   - **Stay Pure Erlang if**: Gains <2x, added complexity not justified

**Expected Outcomes**:

1. Performance comparison report
2. Recommendation: Nx, custom NIF, or pure Erlang
3. If beneficial: prototype implementation
4. If not: document why and alternative optimizations

**Investigation Effort**: 3-4 days
- Day 1: Nx integration spike, basic benchmarks
- Day 2: Comprehensive performance testing
- Day 3: Prototype implementation (if promising)
- Day 4: Documentation and recommendation

**References**:
- Nx: https://github.com/elixir-nx/nx
- EXLA: https://github.com/elixir-nx/nx/tree/main/exla
- Rustler (for NIF alternative): https://github.com/rusterlium/rustler

## Dependencies

### External Dependencies

- fprof, eprof (profiling)
- timer (benchmarking)

### Internal Dependencies

- All previously refactored modules
- Robustness features (v0.8.0)

## Effort Estimate

| Task | Estimate |
|------|----------|
| Profiling setup | 1 day |
| Forward propagation optimization | 2 days |
| Perturbation optimization | 1 day |
| Mnesia optimization | 1.5 days |
| Dead code removal | 1 day |
| Benchmark suite | 1.5 days |
| Documentation | 1 day |
| Verification | 1 day |
| **Total** | **10 days** |

## Risks

| Risk | Mitigation |
|------|------------|
| Optimization breaks behavior | Verification tests |
| Premature optimization | Profile first |
| Cache invalidation bugs | TTL and clear mechanisms |

---

**Version**: 0.9.0
**Phase**: Performance
**Status**: Planned
